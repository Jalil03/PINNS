# Guide Complet du Module [data](file:///c:/Users/JL/OneDrive/Desktop/pinnstorch/pinn_project/part02/train02.py#11-44) de PINNsTorch

## üìã Vue d'Ensemble

Le module `pinnstorch/data` est le **c≈ìur du syst√®me de gestion des donn√©es** pour les Physics-Informed Neural Networks. Il fournit toute l'infrastructure n√©cessaire pour :
- D√©finir des domaines spatiaux et temporels
- G√©n√©rer des maillages de points
- √âchantillonner des points d'entra√Ænement
- Appliquer des conditions aux limites et initiales
- Charger les donn√©es pour l'entra√Ænement

---

## üèóÔ∏è Architecture Globale

```mermaid
graph TD
    A[Domaines] --> B[Mesh/PointCloud]
    B --> C[Samplers]
    C --> D[DataLoader]
    D --> E[PINNDataModule]
    E --> F[PyTorch Lightning Trainer]
    
    A1[Spatial: Interval, Rectangle, RectangularPrism] --> A
    A2[Time: TimeDomain] --> A
    A3[Data: PointCloudData] --> A
    
    C1[MeshSampler] --> C 
    C2[BoundaryCondition] --> C
    C3[InitialCondition] --> C
```

---

## 1Ô∏è‚É£ Dossier `domains/` - D√©finition des Domaines

### üìÇ Fichiers
- `spatial.py` - G√©om√©tries spatiales (1D, 2D, 3D)
- `time.py` - Domaine temporel
- `point_cloud.py` - Structure de donn√©es pour nuages de points

---

### üîπ **`spatial.py`** - Domaines Spatiaux

Trois classes pour d√©finir des g√©om√©tries spatiales :

#### **1. Classe `Interval` (1D)**

```python
Interval(x_interval=[0, 1], shape=[100])
```

**R√¥le** : D√©finit un intervalle 1D discr√©tis√©
- `x_interval` : Bornes [x_min, x_max]
- `shape` : Nombre de points dans l'intervalle

**M√©thode cl√©** :
- `generate_mesh(t_points)` : G√©n√®re un maillage 1D r√©p√©t√© pour chaque instant t
  - Retourne un array de forme (N_spatial, N_time, 1)

**Exemple** :
```python
interval = Interval(x_interval=[0, 10], shape=[50])
mesh = interval.generate_mesh(t_points=100)
# mesh.shape = (50, 100, 1)
```

---

#### **2. Classe `Rectangle` (2D)**

```python
Rectangle(x_interval=[0, 1], y_interval=[0, 1], shape=[50, 50])
```

**R√¥le** : D√©finit un rectangle 2D
- `x_interval`, `y_interval` : Bornes en x et y
- `shape` : [N_x, N_y] points dans chaque direction

**M√©thode cl√©** :
- `generate_mesh(t_points)` : Cr√©e une grille 2D avec `meshgrid`
  - Retourne un array de forme (N_x √ó N_y, N_time, 2)

**Exemple** :
```python
rect = Rectangle(x_interval=[-1, 1], y_interval=[-1, 1], shape=[30, 30])
mesh = rect.generate_mesh(t_points=200)
# mesh.shape = (900, 200, 2)  # 30√ó30 points spatiaux
```

---

#### **3. Classe `RectangularPrism` (3D)**

```python
RectangularPrism(x_interval, y_interval, z_interval, shape=[20, 20, 20])
```

**R√¥le** : D√©finit un prisme rectangulaire 3D
- M√™me logique que Rectangle mais avec dimension z
- Retourne un array de forme (N_x √ó N_y √ó N_z, N_time, 3)

---

### üîπ **`time.py`** - Domaine Temporel

#### **Classe `TimeDomain`**

```python
TimeDomain(t_interval=[0, 1], t_points=100)
```

**R√¥le** : Discr√©tise le temps
- `t_interval` : Intervalle temporel [t_start, t_end]
- `t_points` : Nombre de points temporels

**M√©thode cl√©** :
- `generate_mesh(spatial_points)` : Cr√©e un mesh temporel r√©p√©t√© pour chaque point spatial
  - Retourne un array de forme (N_spatial, N_time, 1)

**Exemple** :
```python
time_domain = TimeDomain(t_interval=[0, 5], t_points=100)
time_mesh = time_domain.generate_mesh(spatial_points=500)
# time_mesh.shape = (500, 100, 1)
```

---

### üîπ **`point_cloud.py`** - Structure de Donn√©es

#### **Dataclass `PointCloudData`**

```python
@dataclass
class PointCloudData:
    spatial: List[np.array]      # Liste de coordonn√©es spatiales [x, y, ...]
    time: np.array               # Coordonn√©es temporelles
    solution: Dict[str, np.array] # Solutions exactes {"u": ..., "v": ..., "p": ...}
```

**R√¥le** : Conteneur pour donn√©es de nuages de points (utilis√© avec `PointCloud`)

**Exemple d'utilisation** :
```python
data = PointCloudData(
    spatial=[x_coords, y_coords],  # x: (N, 1), y: (N, 1)
    time=[t_coords],                # t: (T, 1)
    solution={"u": u_exact, "v": v_exact}  # (N, T)
)
```

---

## 2Ô∏è‚É£ Dossier `mesh/` - G√©n√©ration de Maillages

### üìÇ Fichier : `mesh.py`

Contient deux classes principales : `Mesh` et `PointCloud`

---

### üîπ **Classe de Base `MeshBase`**

Fournit des m√©thodes utilitaires partag√©es :

| M√©thode | Description |
|---------|-------------|
| `domain_bounds()` | Calcule les bornes du domaine (lb, ub) |
| `on_lower_boundary(solution_names)` | Extrait les points sur la fronti√®re inf√©rieure |
| `on_upper_boundary(solution_names)` | Extrait les points sur la fronti√®re sup√©rieure |
| `on_initial_boundary(solution_names, idx)` | Extrait les points √† l'instant initial (t=idx) |
| `collection_points(N_f, use_lhs)` | G√©n√®re N_f points de collocation (al√©atoires ou LHS) |
| `flatten_mesh(solution_names)` | Aplatit le mesh en listes 1D |

---

### üîπ **Classe `Mesh`**

**Usage** : Quand vous d√©finissez explicitement les domaines spatial et temporel

```python
Mesh(
    spatial_domain=Rectangle(...),
    time_domain=TimeDomain(...),
    root_dir="./data",
    read_data_fn=my_read_function,
    lb=[x_min, y_min, t_min],  # Optionnel
    ub=[x_max, y_max, t_max]   # Optionnel
)
```

**Workflow** :
1. Appelle [read_data_fn(root_dir)](file:///c:/Users/JL/OneDrive/Desktop/pinnstorch/pinn_project/part02/train02.py#11-44) pour charger les solutions
2. G√©n√®re les maillages spatial et temporel via `generate_mesh()`
3. Stocke les bornes du domaine (lb, ub)

**Attributs** :
- `spatial_domain_mesh` : Array (N_spatial, N_time, spatial_dim)
- `time_domain_mesh` : Array (N_spatial, N_time, 1)
- `solution` : Dict {"u": array, "v": array, ...}

---

### üîπ **Classe `PointCloud`**

**Usage** : Quand vous avez des donn√©es de nuage de points (donn√©es r√©elles ou synth√©tiques)

```python
PointCloud(
    root_dir="./data",
    read_data_fn=my_read_function,  # Doit retourner PointCloudData
    lb=None,
    ub=None
)
```

**Workflow** :
1. Appelle [read_data_fn(root_dir)](file:///c:/Users/JL/OneDrive/Desktop/pinnstorch/pinn_project/part02/train02.py#11-44) ‚Üí retourne un objet `PointCloudData`
2. Extrait `spatial`, `time`, `solution`
3. Construit `spatial_domain_mesh` et `time_domain_mesh` en r√©p√©tant les coordonn√©es

**Diff√©rence avec `Mesh`** :
- `Mesh` : Vous d√©finissez la g√©om√©trie (Rectangle, Interval, etc.)
- `PointCloud` : Vous fournissez directement les coordonn√©es des points

**Exemple dans votre projet** :
```python
# Dans train.py et train02.py
mesh = PointCloud(root_dir=data_dir, read_data_fn=read_data_fn)
```

---

## 3Ô∏è‚É£ Dossier `sampler/` - √âchantillonnage des Points

Les samplers extraient des sous-ensembles de points du mesh pour l'entra√Ænement.

---

### üîπ **Classe de Base `SamplerBase`**

Toutes les classes de sampler h√©ritent de `SamplerBase`.

**Attributs communs** :
- `spatial_domain_sampled` : Points spatiaux √©chantillonn√©s
- `time_domain_sampled` : Points temporels √©chantillonn√©s
- `solution_sampled` : Solutions exactes √©chantillonn√©es

**M√©thodes cl√©s** :
- `sample_mesh(num_sample, flatten_mesh)` : √âchantillonne `num_sample` points al√©atoirement
- `convert_to_tensor(arrays)` : Convertit NumPy ‚Üí PyTorch
- `loss_fn(inputs, loss, functions)` : Calcule la perte (appelle `_loss_fn` sp√©cifique)
- `__len__()` : Nombre de points
- `__getitem__(idx)` : Acc√®s index√© aux donn√©es

---

### üîπ **Classe `MeshSampler`**

**R√¥le** : √âchantillonneur principal pour les points de solution et de collocation

```python
MeshSampler(
    mesh=my_mesh,
    idx_t=None,                    # Indice temporel sp√©cifique (optionnel)
    num_sample=5000,               # Nombre de points √† √©chantillonner
    solution=["u", "v"],           # Noms des variables de solution
    collection_points=["f_u", "f_v"],  # Points de collocation (r√©sidus PDE)
    use_lhs=True                   # Utiliser Latin Hypercube Sampling
)
```

**Modes d'utilisation** :

#### **Mode 1 : Points de solution uniquement**
```python
sampler = MeshSampler(
    mesh=mesh,
    num_sample=5000,
    solution=["u", "v", "p"]
)
# √âchantillonne 5000 points du mesh avec solutions exactes
```

#### **Mode 2 : Points de collocation uniquement** (r√©sidus PDE)
```python
sampler = MeshSampler(
    mesh=mesh,
    num_sample=5000,
    collection_points=["f_u", "f_v"]
)
# G√©n√®re 5000 points al√©atoires pour √©valuer les r√©sidus PDE
```

#### **Mode 3 : Points √† un instant sp√©cifique**
```python
sampler = MeshSampler(
    mesh=mesh,
    idx_t=100,  # √Ä t = temps[100]
    solution=["u", "v"]
)
# Extrait tous les points spatiaux √† l'instant t=100
```

**M√©thode `_loss_fn`** :
- Si `collection_points` : Appelle [pde_fn()](file:///c:/Users/JL/OneDrive/Desktop/pinnstorch/pinn_project/train.py#43-75) pour calculer les r√©sidus
- Si `solution` : Compare avec les solutions exactes
- Combine les deux pertes

---

### üîπ **Classe `DirichletBoundaryCondition`**

**R√¥le** : Impose des conditions de Dirichlet sur les fronti√®res

```python
DirichletBoundaryCondition(
    mesh=my_mesh,
    solution=["u", "v"],
    num_sample=500,
    boundary_fun=None,  # Fonction optionnelle pour modifier les valeurs aux fronti√®res
    discrete=False
)
```

**Workflow** :
1. Extrait les points sur les fronti√®res sup√©rieure et inf√©rieure via `on_upper_boundary()` et `on_lower_boundary()`
2. Concat√®ne ces points
3. √âchantillonne `num_sample` points al√©atoires parmi eux

**Exemple** : Fixer u=0 et v=0 aux bords d'un domaine

---

### üîπ **Classe `PeriodicBoundaryCondition`**

**R√¥le** : Impose des conditions p√©riodiques (solution identique aux fronti√®res oppos√©es)

**Exemple** : Pour un domaine p√©riodique comme un anneau

---

### üîπ **Classe `InitialCondition`**

**R√¥le** : Impose la condition initiale √† t=0

```python
InitialCondition(
    mesh=my_mesh,
    num_sample=1000,
    solution=["u", "v"],
    initial_fun=None  # Fonction optionnelle pour d√©finir u(x, t=0)
)
```

**Workflow** :
1. Extrait les points √† t=0 via `on_initial_boundary()`
2. Si `initial_fun` est fourni, l'applique pour calculer la solution initiale
3. √âchantillonne `num_sample` points

---

### üîπ **Classe `DiscreteMeshSampler`**

**R√¥le** : Pour les probl√®mes temporellement discrets (m√©thodes Runge-Kutta)

**Diff√©rence** : Ne consid√®re pas le temps comme une variable continue, mais comme des pas discrets

---

## 4Ô∏è‚É£ Dossier `dataloader/` - Chargement des Donn√©es

### üìÇ Fichier : `dataloader.py`

### üîπ **Classe `PINNDataLoader`**

**R√¥le** : DataLoader custom optimis√© pour les PINNs

```python
PINNDataLoader(
    dataset=my_sampler,  # Un objet Sampler
    batch_size=None,     # Si None, tout le dataset en un batch
    ignore=False,        # Ignorer les batchs incomplets
    shuffle=False        # M√©langer les donn√©es
)
```

**Caract√©ristiques** :
- Plus rapide que `torch.utils.data.DataLoader` standard
- Supporte le batching et le shuffling
- Si `batch_size=None`, retourne tout le dataset d'un coup (typique pour PINNs)

**M√©thodes** :
- `__iter__()` : Initialise l'it√©ration
- `__next__()` : Retourne le prochain batch
- `__len__()` : Nombre de batchs

---

## 5Ô∏è‚É£ Fichier `pinn_datamodule.py`

### üîπ **Classe `PINNDataModule`**

**R√¥le** : Module de donn√©es PyTorch Lightning qui orchestre tous les dataloaders

```python
PINNDataModule(
    train_datasets=[sampler1, sampler2, ...],  # Liste de samplers pour l'entra√Ænement
    val_dataset=val_sampler,                   # Un seul sampler pour validation
    test_dataset=test_sampler,
    pred_dataset=pred_sampler,
    batch_size=None,
    num_workers=0,
    pin_memory=False
)
```

**Workflow** :
1. `setup(stage)` : Initialise les dataloaders
   - Pour chaque `train_dataset`, cr√©e un `PINNDataLoader`
   - Stocke les `loss_fn` associ√©es dans `function_mapping`
2. `train_dataloader()` : Retourne les dataloaders d'entra√Ænement
3. `val_dataloader()` : Retourne le dataloader de validation
4. `test_dataloader()`, `predict_dataloader()` : Idem pour test et pr√©diction

**Particularit√©** :
- Supporte **plusieurs datasets d'entra√Ænement** simultan√©ment (ex: points de solution + points de collocation + conditions aux limites)
- Chaque dataset a sa propre `loss_fn`

---

## üîÑ Flux de Donn√©es Complet

Voici comment tout s'assemble dans votre projet :

### **√âtape 1 : D√©finir les domaines ou charger les donn√©es**

```python
# Option A: Avec domaines explicites
spatial = Rectangle(x_interval=[-1, 1], y_interval=[-1, 1], shape=[50, 50])
temp = TimeDomain(t_interval=[0, 1], t_points=100)
mesh = Mesh(spatial_domain=spatial, time_domain=temp, 
            root_dir="./data", read_data_fn=read_data_fn)

# Option B: Avec nuage de points (votre cas)
mesh = PointCloud(root_dir="./data", read_data_fn=read_data_fn)
```

### **√âtape 2 : Cr√©er des samplers**

```python
# Sampler pour points de solution
solution_sampler = MeshSampler(
    mesh=mesh,
    num_sample=5000,
    solution=["u", "v"]
)

# Sampler pour points de collocation (r√©sidus PDE)
collocation_sampler = MeshSampler(
    mesh=mesh,
    num_sample=5000,
    collection_points=["f_u", "f_v"]
)

# Condition initiale
ic_sampler = InitialCondition(
    mesh=mesh,
    num_sample=1000,
    solution=["u", "v"]
)
```

### **√âtape 3 : Cr√©er le DataModule**

```python
data_module = PINNDataModule(
    train_datasets=[solution_sampler, collocation_sampler, ic_sampler],
    val_dataset=MeshSampler(mesh=mesh, solution=["u", "v", "p"])
)
```

### **√âtape 4 : Entra√Æner avec PyTorch Lightning**

```python
trainer = Trainer(max_epochs=10000, ...)
trainer.fit(model, datamodule=data_module)
```

---

## üìä Exemple Concret : Votre Projet

Dans [train.py](file:///c:/Users/JL/OneDrive/Desktop/pinnstorch/pinn_project/train.py) et [train02.py](file:///c:/Users/JL/OneDrive/Desktop/pinnstorch/pinn_project/part02/train02.py) :

### **1. Fonction [read_data_fn](file:///c:/Users/JL/OneDrive/Desktop/pinnstorch/pinn_project/part02/train02.py#11-44)**

```python
def read_data_fn(root_path):
    # Charge les donn√©es
    x, y, t = ...  # Coordonn√©es
    u, v, p = ...  # Solutions
    
    return PointCloudData(
        spatial=[x, y],
        time=[t],
        solution={"u": u, "v": v, "p": p}
    )
```

### **2. Configuration [config.yaml](file:///c:/Users/JL/OneDrive/Desktop/pinnstorch/pinn_project/configs/config.yaml)**

```yaml
mesh:
  _target_: pinnstorch.data.PointCloud
  root_dir: ${paths.data_dir}
  read_data_fn: ???  # Sera rempli par pinnstorch.train()

train_datasets:
  - mesh_sampler:
      _target_: pinnstorch.data.MeshSampler
      num_sample: 5000
      solution: [u, v]          # Points avec solutions exactes
      collection_points: [f_u, f_v]  # Points pour r√©sidus PDE
```

### **3. Instanciation automatique par Hydra**

```python
pinnstorch.train(cfg, read_data_fn=read_data_fn, pde_fn=pde_fn, output_fn=output_fn)
```

Cette fonction :
1. Instancie `PointCloud` avec [read_data_fn](file:///c:/Users/JL/OneDrive/Desktop/pinnstorch/pinn_project/part02/train02.py#11-44)
2. Cr√©e les `MeshSampler` configur√©s
3. Assemble le `PINNDataModule`
4. Lance l'entra√Ænement

---

## üéØ R√©sum√© des Composants

| Composant | R√¥le |
|-----------|------|
| **`Interval`, `Rectangle`, `RectangularPrism`** | D√©finissent la g√©om√©trie spatiale |
| **`TimeDomain`** | D√©finit la discr√©tisation temporelle |
| **`PointCloudData`** | Structure de donn√©es pour nuages de points |
| **`Mesh`** | G√©n√®re des maillages √† partir de domaines d√©finis |
| **`PointCloud`** | G√©n√®re des maillages √† partir de points arbitraires |
| **`MeshSampler`** | √âchantillonne des points de solution et/ou collocation |
| **`DirichletBoundaryCondition`** | Impose des conditions aux fronti√®res |
| **`InitialCondition`** | Impose la condition initiale |
| **`PINNDataLoader`** | DataLoader optimis√© pour PINNs |
| **`PINNDataModule`** | Orchestre tous les dataloaders (PyTorch Lightning) |

---

## üí° Points Cl√©s √† Retenir

1. **Deux approches** :
   - `Mesh` : G√©om√©trie d√©finie explicitement (Interval, Rectangle, etc.)
   - `PointCloud` : Points arbitraires (vos donn√©es r√©elles ou synth√©tiques)

2. **√âchantillonnage flexible** :
   - Points de solution (comparaison avec donn√©es exactes)
   - Points de collocation (√©valuation des r√©sidus PDE)
   - Conditions aux limites et initiales

3. **Latin Hypercube Sampling (LHS)** :
   - Utilis√© pour les points de collocation
   - Meilleure couverture du domaine que le sampling al√©atoire uniforme

4. **Int√©gration PyTorch Lightning** :
   - `PINNDataModule` g√®re automatiquement train/val/test/predict
   - Supporte plusieurs datasets d'entra√Ænement avec diff√©rentes loss functions

5. **Configuration Hydra** :
   - Tout est configurable via YAML
   - Instantiation automatique des classes avec `_target_:`
